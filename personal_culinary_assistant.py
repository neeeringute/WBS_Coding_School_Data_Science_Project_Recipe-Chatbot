# -*- coding: utf-8 -*-
"""personal_culinary_assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LzPYsYMQSQ6ZEwETC3E-AvvzhDfinpT5
"""

!pip install PyPDF2
!pip install gradio
!pip install pymupdf

# Commented out IPython magic to ensure Python compatibility.
 %%bash
 pip install -qqq -U langchain-groq
 pip install -qqq -U langchain-huggingface
 pip install -qqq -U langchain
 pip install -qqq -U langchain-community
 pip install -qqq -U faiss-cpu
 pip install huggingface_hub[hf_xet]

# Importing the Colab 'files' module for file upload functionality
from google.colab import files

# Allow the user to upload a file, typically a PDF in this case
# 'uploaded' will contain a dictionary with file names as keys and their byte content as values
uploaded = files.upload()

# List all files and directories in the '/content' directory of Google Colab
!ls /content

import fitz  # PyMuPDF

# Extract text from PDF
def extract_text_from_pdf(file_path):
    doc = fitz.open(file_path)
    text = ""
    for page in doc:
        text += page.get_text()
    doc.close()
    return text

# Specify the file path
file_path = "/content/101_square_meals.pdf"
pdf_text = extract_text_from_pdf(file_path)

# Print the first 1000 characters to inspect
print(pdf_text[:1000])

# Define a list of recipe categories
recipe_categories = [
    "Desserts", "Salads", "Snacks & Light Meals", "Vegetarian",
    "Chicken & Turkey", "Fish", "Beef, Lamb & Pork", "Soups", "Breakfast"
]

# Print the list of recipe categories
print("Recipe Categories:", recipe_categories)

# Define a dictionary for measurement conversions
measurement_conversions = {
    "Weight": {
        "5 g": "¬º oz", "15 g": "¬Ω oz", "25 g": "1 oz", "50 g": "2 oz",
        "85 g": "3 oz", "110 g": "4 oz (¬º lb)", "225 g": "8 oz (¬Ω lb)",
        "450 g": "16 oz (1 lb)", "900 g": "32 oz (2 lb)"
    },
    "Oven Temperature": {
        "120¬∞C": {"Fahrenheit": "250¬∞F", "Gas mark": "Half"},
        "140¬∞C": {"Fahrenheit": "275¬∞F", "Gas mark": "1"},
        "180¬∞C": {"Fahrenheit": "350¬∞F", "Gas mark": "4"},
        "200¬∞C": {"Fahrenheit": "400¬∞F", "Gas mark": "6"},
        "220¬∞C": {"Fahrenheit": "425¬∞F", "Gas mark": "7"}
    },
    "Volume": {
        "¬Ω tsp": "2.5 ml", "1 tsp": "5 ml", "¬Ω tbsp": "7.5 ml",
        "1 tbsp": "15 ml", "¬Ω cup": "120 ml", "1 cup": "240 ml",
        "2 cups": "480 ml"
    }
}

# Print the measurement conversions
print("Measurement Conversions:", measurement_conversions)

# Define a dictionary for common cooking abbreviations
abbreviations = {
    "Teaspoon": "tsp",
    "Dessertspoon": "dstsp",
    "Tablespoon": "tbsp",
    "Fluid ounce": "fl oz",
    "Ounce": "oz",
    "Millilitre": "ml",
    "Litre": "l",
    "Pint": "pt",
    "Pound": "lb",
    "Gram": "g",
    "Kilogram": "kg",
    "Celsius": "¬∞C",
    "Fahrenheit": "¬∞F"
}

# Print the abbreviations dictionary
print("Abbreviations:", abbreviations)

# Recipes
recipes = {
    "Breakfast": [
        "French toast", "Omelette", "Poached eggs", "Scrambled eggs", "Porridge", "Fruity, nutty muesli"
    ],
    "Soups": [
        "Chicken soup", "Farmhouse vegetable soup", "Mushroom soup",
        "Cream of vegetable soup", "Lentil soup", "Minestrone soup",
        "Leek and potato soup", "Spicy lentil and tomato soup"
    ],
    "Beef, Lamb & Pork": [
        "Spaghetti Bolognese", "Cottage pie", "Beef burgers", "Meat loaf",
        "Chilli con carne", "Meatballs", "Beef tacos", "Beef stew",
        "Pork stir-fry", "Beef or lamb curry", "Grilled pork chops with apple sauce",
        "Pork and pepper kebabs", "Pork, chickpea and sweet potato stew", "Honey roast ham"
    ],
    "Fish": [
        "Baked, stuffed fish", "Fish pie", "Tuna pasta bake", "Peri-peri salmon",
        "Fish fingers", "Soy salmon", "Sun-dried tomato cod", "Grilled salmon cutlets"
    ],
    "Chicken & Turkey": [
        "Chicken and vegetable casserole", "Chicken curry", "Chicken in tomato sauce",
        "Barbeque chicken drumsticks", "Baked chicken with cheese and mustard",
        "Coronation chicken", "Roast chicken and vegetables", "Chicken fingers",
        "Chicken fajitas", "Chargrilled chicken kebabs", "Turkey pie"
    ],
    "Vegetarian": [
        "Spicy potato wedges", "Spanish tortilla", "Vegetable stir-fry with eggy rice",
        "Midweek Mexican beans", "Roasted vegetable pasta", "Sweet potato satay stew",
        "Moroccan vegetable tagine", "Thai butternut squash curry",
        "Rice and vegetable hotpot", "Lentil and vegetable stew", "Peas and rice"
    ],
    "Snacks & Light Meals": [
        "A graze box", "Packed lunch", "Baked potatoes", "Pancakes",
        "Quiche", "Potato cakes", "Toasted cheese", "Guacamole",
        "Crunchy fruit and yoghurt", "Hummus", "Sweet potato crisps", "Fruit salad",
        "Kiwi, grape and apple smoothie", "Red rooster smoothie",
        "Nectarine, strawberry and banana smoothie", "Peary nice smoothie"
    ],
    "Salads": [
        "10-minute couscous salad", "Chicken Caesar salad", "Hot pasta salad",
        "Warm chickpea salad", "Mexican bean salad", "Chicken and pasta salad",
        "BLT pasta salad", "Warm chicken noodle salad", "Tuna rice salad",
        "Lemony roast chicken couscous", "Mixed bean and rice salad", "Greek pasta salad"
    ],
    "Desserts & Breads": [
        "Wholemeal bread", "Queen cakes", "Wholemeal scones", "Irish tea brack",
        "Banana bread", "Carrot cake", "Coffee cake", "Apple or rhubarb crumble",
        "Bread and butter pudding", "Simple sponge", "Simple oat bread",
        "Ultimate basic muffins", "Eton mess"
    ]
}


# Print the structured recipes
print("Recipes by Category:", recipes)

introduction = """
The food we eat affects our health and well-being, and budget plays an important role in what food we buy and prepare.
This recipe book is designed to take this into consideration and provides easy-to-prepare, low-budget, tasty, yet highly nutritious meals.
You will find sections containing useful tips on shopping, home freezing, and meal planning.
"""

print("Introduction:", introduction)

food_safety = {
    "Introduction": "The food we eat affects our health and well-being...",
    "Food Safety": [
        "Store refrigerated and frozen foods as soon as possible.",
        "Keep raw meat in sealed containers on the bottom shelf of the fridge.",
        "Eat leftovers within 3 days."
    ],
    "Freezing Tips": [
        "Do not put food in the freezer when it's still hot.",
        "Your freezer should be at ‚Äì18¬∞C.",
        "Do not freeze any foods after their 'use by' date."
    ],
    "Defrosting Tips": [
        "Defrost food in the fridge for at least 24 hours for every 2‚Äì2.5 kg.",
        "Cook or eat defrosted food within 24 hours.",
        "Do not refreeze thawed food."
    ]
}

print("Food Safety", food_safety)

import json

# Combine recipe data into a dictionary
data = {
    "Categories": recipe_categories,
    "Recipes": recipes,
    "Measurements": measurement_conversions,
    "Abbreviations": abbreviations,
    "Introduction": introduction,
    "Food Safety": food_safety
}

# Save the data as a JSON file
with open("recipe_book_data.json", "w") as file:
    json.dump(data, file, indent=4)

# Confirmation message
print("Data saved to recipe_book_data.json")

# Load the JSON file to verify its content
with open("recipe_book_data.json", "r") as file:
    loaded_data = json.load(file)

# Print the loaded data
print(json.dumps(loaded_data, indent=4))

import json

# Load the JSON file to verify its content
with open("recipe_book_data.json", "r") as file:
    loaded_data = json.load(file)

# Print the loaded data (for verification)
print(json.dumps(loaded_data, indent=4))

# Save the JSON data to your Downloads folder
output_file_path = "C:\\Users\\neeer\\Downloads\\recipe_book_copy.json"
with open(output_file_path, "w") as file:
    json.dump(loaded_data, file, indent=4)

print(f"File saved successfully at: {output_file_path}")

# List all categories
def list_categories(data):
    return data["Categories"]

# Get recipes by category
def get_recipes_by_category(data, category):
    return data["Recipes"].get(category, "Category not found.")

# Search for a specific recipe
def search_recipe(data, recipe_name):
    for category, recipes in data["Recipes"].items():
        if recipe_name in recipes:
            return {"Category": category, "Recipe Name": recipe_name}
    return "Recipe not found."

# Example usage
categories = list_categories(loaded_data)
print("Categories:", categories)

soups = get_recipes_by_category(loaded_data, "Soups")
print("Soups:", soups)

search_result = search_recipe(loaded_data, "Omelette")
print("Search Result:", search_result)

from langchain_groq import ChatGroq
from google.colab import userdata

llm = ChatGroq(
    temperature=0.7,
    groq_api_key="your_actual_groq_api_key_here",
    model_name="llama3-70b-8192"
)

print("ChatGroq model initialized.")

import json
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain_core.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain_groq import ChatGroq

# Load recipe data
with open("recipe_book_data.json", "r") as file:
    recipe_data = json.load(file)

print("Recipe data loaded successfully.")

from langchain.schema import Document

# Convert recipes into plain text for Document objects
recipe_texts = []
for category, recipes in recipe_data["Recipes"].items():
    for recipe in recipes:
        if isinstance(recipe, dict):  # For detailed recipes
            recipe_text = f"Recipe Name: {recipe['Recipe Name']}\nCategory: {category}\n"
            recipe_text += "Ingredients:\n" + "\n".join(recipe.get("Ingredients", [])) + "\n"
            recipe_text += "Steps:\n" + "\n".join(recipe.get("Steps", [])) + "\n"
        else:
            recipe_text = f"Recipe Name: {recipe}\nCategory: {category}\n"
        recipe_texts.append(recipe_text)

# Create Document objects
documents = [Document(page_content=text) for text in recipe_texts]
print(f"Prepared {len(documents)} documents.")

from langchain.text_splitter import RecursiveCharacterTextSplitter

# Define text splitter for recipes
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=800,       # Each chunk contains 800 characters
    chunk_overlap=150     # 150 characters overlap between chunks
)

# Split the documents into chunks
docs = text_splitter.split_documents(documents)

print(f"Split into {len(docs)} chunks.")

# Print the first 3 chunks to verify
for i, doc in enumerate(docs[:3]):
    print(f"Chunk {i+1}:")
    print(doc.page_content)
    print("-" * 50)

# Skip splitting for small recipes and use the original documents
print(f"Prepared {len(documents)} documents.")
for i, doc in enumerate(documents[:3]):  # Preview the first 3 documents
    print(f"Document {i+1}:")
    print(doc.page_content)
    print("-" * 50)

# Verify prepared documents
print(f"Prepared {len(documents)} documents.")
for i, doc in enumerate(documents[:3]):  # Preview the first 3 documents
    print(f"Document {i+1}:")
    print(doc.page_content)
    print("-" * 50)

from langchain_huggingface import HuggingFaceEmbeddings

# embeddings
embedding_model = "sentence-transformers/all-MiniLM-l6-v2"
embeddings_folder = "/content/"

embeddings = HuggingFaceEmbeddings(model_name=embedding_model,
                                   cache_folder=embeddings_folder)

sample_text = "What can I make with tomatoes and basil?"
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-l6-v2")
vector = embeddings.embed_query(sample_text)
print(vector)

# Assume `documents` is a list of Document objects prepared earlier
vector_db = FAISS.from_documents(documents, embeddings)

# Save the FAISS index to a specified path
vector_db.save_local("/content/faiss_index")

print("FAISS index created and saved.")

!ls /content

from langchain.vectorstores import FAISS
vector_db = FAISS.load_local("/content/faiss_index", embeddings, allow_dangerous_deserialization=True)
retriever = vector_db.as_retriever(search_kwargs={"k": 5})

print("FAISS index loaded and retriever created.")

from google.colab import files

uploaded = files.upload()

!pip install -qqq -U streamlit
!npm install -qqq -U localtunnel

# Commented out IPython magic to ensure Python compatibility.
#for use
 %%writefile rag_app.py
 
 from langchain.vectorstores import FAISS
 from langchain.prompts import PromptTemplate
 from langchain.memory import ConversationBufferMemory
 from langchain.chains import ConversationalRetrievalChain
 from langchain_huggingface import HuggingFaceEmbeddings
 from langchain_groq import ChatGroq
 import streamlit as st
 
 # üç≥ Initialize the embeddings
 embedding_model = "sentence-transformers/all-MiniLM-l6-v2"
 embeddings_folder = "/content/"
 embeddings = HuggingFaceEmbeddings(model_name=embedding_model, cache_folder=embeddings_folder)
 
 # üóÇÔ∏è Load the FAISS index
 vector_db = FAISS.load_local("/content/faiss_index", embeddings, allow_dangerous_deserialization=True)
 retriever = vector_db.as_retriever(search_kwargs={"k": 5})
 
 # ü§ñ Initialize the language model
 llm = ChatGroq(
     model_name="llama3-70b-8192",
     temperature=0.9,
     groq_api_key="your_actual_groq_api_key_here",
     max_tokens=600
 )
 
 # memory
 @st.cache_resource
 def init_memory():
     return ConversationBufferMemory(
         llm=llm,
         input_key="question",
         output_key="answer",
         memory_key="chat_history",
         return_messages=True
     )
 memory = init_memory()
 
 # üìú Define the prompt template
 template = """
 üç¥ You are a cooking assistant chatbot. Answer the user's cooking-related questions.
 - ü•ó Provide recipes when ingredients are given, using metric units (g, kg, ml, l).
 - üç≤ For substitution or technique-related questions, give direct and concise answers.
 - üìñ Structure your responses clearly with headings like "Recipe Name," "Ingredients," and "Instructions" when providing recipes.
 
 üîÑ Conversion Notes:
 - üßÇ Convert solid ingredients from ounces (oz) to grams (g) using 1 oz = 28.35 g.
 - ü•§ Convert liquid ingredients from fluid ounces (fl oz) to milliliters (ml) using 1 fl oz = 29.5735 ml.
 
 üó£Ô∏è Previous conversation:
 {chat_history}
 
 üìö Context:
 {context}
 
 üë©‚Äçüç≥ User's Question:
 {question}
 
 ‚ú® Response:
 """
 
 prompt = PromptTemplate(template=template, input_variables=["context", "question"])
 
 # üõ†Ô∏è Conversational Retrieval Chain setup
 chain_3 = ConversationalRetrievalChain.from_llm(
     llm=llm,
     retriever=retriever,
     memory=memory,
     return_source_documents=True,
     combine_docs_chain_kwargs={"prompt": prompt}
 )
 
 # üåü Streamlit UI
 # Display Header Image
 st.image("/content/_ac756658-e799-4991-8d8b-591643028427.jpeg", use_container_width=True, width=400)
 
 st.title("üç¥ Recipe Chatbot")
 st.header("Your Personal Culinary Assistant")
 st.text("Ask me for recipes, substitutions, or cooking techniques!")
 
 # Chat History
 if "messages" not in st.session_state:
     st.session_state.messages = []
 
 # Display chat messages from history on app rerun
 for message in st.session_state.messages:
     if message["role"] == "user":
         with st.chat_message("user"):
             st.markdown(f"üë©‚Äçüç≥ **You:** {message['content']}")
     else:
         with st.chat_message("assistant"):
             st.markdown(f"ü§ñ **Chatbot:** {message['content']}")
 
 # Input box for user
 if user_input := st.chat_input("Ask your cooking question here:"):
     # Add user's question to chat history
     st.session_state.messages.append({"role": "user", "content": user_input})
 
     # Display user message
     with st.chat_message("user"):
         st.markdown(user_input)
 
     # Begin spinner before answering question
     with st.spinner("Cooking up your answer... üç≥"):
         response = chain_3.invoke({"question": user_input})
         chatbot_response = response["answer"]
 
     # Add assistant response to chat history
     st.session_state.messages.append({"role": "assistant", "content": chatbot_response})
 
     # Display chatbot response
     with st.chat_message("assistant"):
         st.markdown(chatbot_response)
 
 # Footer
 st.markdown(
     "<div style='text-align: center; color: gray; font-size: small;'>"
     "Made with ‚ù§Ô∏è by Neringa Pannem ‚Ä¢ Powered by LangChain, HuggingFace & Groq"
     "</div>",
     unsafe_allow_html=True)
 


!streamlit run rag_app.py &> /content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com
